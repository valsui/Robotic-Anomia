import * as tf from '@tensorflow/tfjs';
import { inputTFData, outputTFData } from './data';
// import { imageToMatrix } from './heatmap';
// source is following example for MNIST - https://js.tensorflow.org/tutorials/mnist.html
// ------- building the model structure and layers --------------
// simplest model in which tensors are consecutively passed from one layer to the next;
const model1 = tf.sequential();

// add first layer - two-dimensional convolutional layer. Convolutions slide a filter window over an image to learn transformations that are spatially invariant (that is, patterns or objects in different parts of the image will be treated the same way).
model1.add(tf.layers.conv2d({
    inputShape: [1, 625, 1], //The shape of the data that will flow into the first layer of the model
    kernelSize: 5, //size of the sliding convolutional filter windows to be applied to the input data (5x5)
    filters: 8, //The number of filter windows of size
    strides: 1, //how many pixels the filter will shift 
    activation: 'relu',
    kernelInitializer: 'VarianceScaling' // method used to randomize the model weights 
}));

//second layer - a max pooling layer. This layer will downsample the result (also known as the activation) from the convolution by computing the maximum value for each sliding window

// model.add(tf.layers.maxPooling2d({
//     poolSize: [2, 2], //The size of the sliding pooling windows to be applied to the input data
//     strides: [2, 2] //step size of sliding window
// }))

// additional layers in the network. Repeating layer structure is a common pattern in neural networks. Let's add a second convolutional layer, followed by another pooling layer to our model. Note that in our second convolutional layer, we're doubling the number of filters from 8 to 16. Input size is inferred from the first layer

model1.add(tf.layers.conv2d({
    kernelSize: 5,
    filters: 16, 
    strides: 1,
    activation: 'relu',
    kernelInitializer: 'VarianceScaling'
}));

// model.add(tf.layers.maxPooling2d({
//     poolSize: [2, 2],
//     strides: [2, 2]
// }));

//flatten output of previous layer
model1.add(tf.layers.flatten());

// adding dense layer - fully connected layer that performs the classification 
//flattens the output of a convolution + pooling layer pair before dense layer - common pattern in NN

model1.add(tf.layers.dense({
    units: 26, // size of output classification 
    kernelInitializer: 'VarianceScaling',
    activation: 'softmax' //activation function of the last layer fro the classification task - usually softmax which normalizes output vector into a probability distribution
}));

//------- defining optimizer and loss function -------
const LEARNING_RATE = 0.3;
const optimizer = tf.train.sgd(LEARNING_RATE); //stochastic gradient descent 

//------- compile the model  ------------------
// using categorical Crossentropy as a loss function which is commonly used to optimize classification tasks - it measures the error between the probability distribution generated by the last layer of our model and the probability distribution given by our label
//evaluation metric is just the accuracy

model1.compile({
    optimizer: optimizer,
    loss: 'categoricalCrossentropy',
    metrics: ['accuracy']
})

//-------- defining BATCH SIZES ---------
// How many examples the model should "see" before making a parameter update.
const BATCH_SIZE = 50;
// How many batches to train the model for.
const TRAIN_BATCHES = 100;

// Every TEST_ITERATION_FREQUENCY batches, test accuracy over TEST_BATCH_SIZE examples.
// Ideally, we'd compute accuracy over the whole test set, but for performance
// reasons we'll use a subset.
const TEST_BATCH_SIZE = 1000;
const TEST_ITERATION_FREQUENCY = 5;

//When we set a BATCH_SIZE of 64, we're batching 64 images at a time, which means the actual shape of our data is [64, 28, 28, 1] (the batch is always the outermost dimension).

// NOTE:* Recall that the inputShape in the config of our first conv2d did not specify the batch size(64).Configs are written to be batch - size - agnostic, so that they are able to accept batches of arbitrary size.

//-------- TRAINING LOOP --------------
//need to define data class that contains the two public methods:
// (1) nextTrainBatch(batchSize)-returns a random batch of images and their labels from the training set
// (2) nextTestBatch(batchSize)-returns a batch of images and their labels from the test set
// for (let i = 0; i < TRAIN_BATCHES; i++) {


//     // repeat with batches
//     //history is what stores our model
//     history = await model.fit(
//         batch.xs.reshape([BATCH_SIZE, 25, 25, 1]),
//         batch.labels,
//         {
//             batchSize: BATCH_SIZE,
//             validationData,
//             epochs: 1
//         });
// }

let array = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0.3333333333333333, 0, 0, 0, 0, 0, 0.5555555555555556, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 0.3333333333333333, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 0.8888888888888888, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3333333333333333, 0.5555555555555556, 0.1111111111111111, 0, 0, 0, 0.5555555555555556, 1, 1, 0.8888888888888888, 0.4444444444444444, 0.8888888888888888, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 0, 0, 0, 0.5555555555555556, 0.8888888888888888, 1, 0.6666666666666666, 0.2222222222222222, 0, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 0.5555555555555556, 0, 0.6666666666666666, 1, 1, 0.5555555555555556, 0.1111111111111111, 0, 0, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 1, 0.7777777777777778, 0, 1, 1, 0.6666666666666666, 0.1111111111111111, 0, 0, 0, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0.8888888888888888, 0.5555555555555556, 0.1111111111111111, 0, 0, 0, 0, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 1, 1, 0.5555555555555556, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3333333333333333, 0.8888888888888888, 0.8888888888888888, 0.5555555555555556, 0.1111111111111111, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2222222222222222, 0.2222222222222222, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];

let test = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7777777777777778, 0.8888888888888888, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 0.7777777777777778, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.5555555555555556, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2222222222222222, 0.1111111111111111, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7777777777777778, 1, 1, 0.6666666666666666, 0.7777777777777778, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 0.6666666666666666, 0.1111111111111111, 0.6666666666666666, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 0.6666666666666666, 0.1111111111111111, 0, 0.4444444444444444, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 1, 0.8888888888888888, 0.5555555555555556, 0.1111111111111111, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.7777777777777778, 1, 1, 0.8888888888888888, 0.3333333333333333, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0.7777777777777778, 0.2222222222222222, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0.7777777777777778, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.6666666666666666, 0.1111111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2222222222222222, 0.1111111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];

let datum = [];
let i = 0;
while ( datum.length < 25 ) {
    datum.push(array.slice(i, i + 25));

    i += 25;
}
let j = 0;
while ( test.length < 25 ) {
    test.push(array.slice(j, j + 25));

    j += 25;
}

let datumTF = tf.tensor2d(datum, [25, 25]);
let labelTF = tf.tensor2d([1], [1,1]);
let testTF = tf.tensor2d(test, [25,25]);


model1.fit(
    inputTFData , outputTFData, {epoch: 1}
).then((history) => console.log(history))


// setTimeout(() => {
//     console.log('answer:',model.predict([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7777777777777778, 0.8888888888888888, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 0.7777777777777778, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.5555555555555556, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2222222222222222, 0.1111111111111111, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7777777777777778, 1, 1, 0.6666666666666666, 0.7777777777777778, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 0.6666666666666666, 0.1111111111111111, 0.6666666666666666, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 1, 1, 0.6666666666666666, 0.1111111111111111, 0, 0.4444444444444444, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 1, 0.8888888888888888, 0.5555555555555556, 0.1111111111111111, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.7777777777777778, 1, 1, 0.8888888888888888, 0.3333333333333333, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0.7777777777777778, 0.2222222222222222, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0.7777777777777778, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8888888888888888, 0.6666666666666666, 0.1111111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2222222222222222, 0.1111111111111111, 0, 0, 0, 0, 0, 0, 0, 0, 0.6666666666666666, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5555555555555556, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))
// }, 10000);

//Notes: Calling model.fit() once on the whole dataset will result in uploading the whole dataset to the GPU, which could freeze the application.

// export default model;

export default model1;